{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "j1BMt4ja28FM"
   },
   "source": [
    "#<b>Milestone 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rCiPVBNbA0Wh"
   },
   "source": [
    "##<b>Problem Definition</b>\n",
    "**The context:** Why is this problem important to solve?<br>\n",
    "**The objectives:** What is the intended goal?<br>\n",
    "**The key questions:** What are the key questions that need to be answered?<br>\n",
    "**The problem formulation:** What is it that we are trying to solve using data science?\n",
    "\n",
    "## <b>Data Description </b>\n",
    "\n",
    "There are a total of 24,958 train and 2,600 test images (colored) that we have taken from microscopic images. These images are of the following categories:<br>\n",
    "\n",
    "\n",
    "**Parasitized:** The parasitized cells contain the Plasmodium parasite which causes malaria<br>\n",
    "**Uninfected:** The uninfected cells are free of the Plasmodium parasites<br>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vGsTRO4XBWKn"
   },
   "source": [
    "## <b>Important Notes</b>\n",
    "\n",
    "- This notebook can be considered a guide to refer to while solving the problem. The evaluation will be as per the Rubric shared for each Milestone. Unlike previous courses, it does not follow the pattern of the graded questions in different sections. This notebook would give you a direction on what steps need to be taken in order to get a viable solution to the problem. Please note that this is just one way of doing this. There can be other 'creative' ways to solve the problem and we urge you to feel free and explore them as an 'optional' exercise. \n",
    "\n",
    "- In the notebook, there are markdowns cells called - Observations and Insights. It is a good practice to provide observations and extract insights from the outputs.\n",
    "\n",
    "- The naming convention for different variables can vary. Please consider the code provided in this notebook as a sample code.\n",
    "\n",
    "- All the outputs in the notebook are just for reference and can be different if you follow a different approach.\n",
    "\n",
    "- There are sections called **Think About It** in the notebook that will help you get a better understanding of the reasoning behind a particular technique/step. Interested learners can take alternative approaches if they want to explore different techniques. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HDM89XHyCxrA"
   },
   "source": [
    "### Accessing AWS Sagemaker"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Upon loading the AWS Sagemaker, it is important to load the packages with this command line."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#!pip install tensorflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "S3 bucket system is not hierarchal; the file structure is a pre-fix that you can access using the list_objects function and setting the prefix, which is similar to a filepath. When running get_execution_role, you are able to check the role permissions and add the list-bucket in-line policy if permission is not allowed with the existing role. Boto3 is the open-source code used to create, upload files, and access files off of the S3 bucket."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UC8-yLUUCcWh"
   },
   "source": [
    "### <b>Loading libraries</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "id": "iixNDZWs1ZPL"
   },
   "outputs": [],
   "source": [
    "#Importing libraries required to load the data\n",
    "\n",
    "import zipfile\n",
    "import os\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Conv2D, MaxPool2D, BatchNormalization, Dropout, Flatten, LeakyReLU, GlobalAvgPool2D\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras import optimizers\n",
    "\n",
    "#to ignore warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import boto3\n",
    "\n",
    "# Remove the limit from the number of displayed columns and rows. It helps to see the entire dataframe while printing it\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "pd.set_option(\"display.max_rows\", 200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nCqJk2XpCnJi"
   },
   "source": [
    "### <b>Data Loading with Boto 3</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_syvBdMlDTsr"
   },
   "source": [
    "**Note:** \n",
    "- You must download the dataset from the link provided on Olympus and upload the same on your Google drive before executing the code in the next cell.\n",
    "- In case of any error, please make sure that the path of the file is correct as the path may be different for you."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "ufMU62DICjLV"
   },
   "outputs": [],
   "source": [
    "#File extraction was done prior to this program.\n",
    "\n",
    "#Storing the path of the data file from the Google drive\n",
    "#not sure if this path needs to be updated everytime SageMaker is run\n",
    "#path = path + '/cell_images.zip'\n",
    "\n",
    "#The data is provided as a zip file so we need to extract the files from the zip file\n",
    "#with zipfile.ZipFile(path, 'r') as zip_ref:\n",
    "#    zip_ref.extractall()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IW3fDq7gF4Hw"
   },
   "source": [
    "The extracted folder has different folders for train and test data which further contains the different sizes of images for parasitized and uninfected cells within the respective folder name. \n",
    "\n",
    "The size of all images must be the same and should be converted to 4D arrays so that they can be used as an input for the convolutional neural network. Also, we need to create the labels for both types of images to be able to train and test the model. \n",
    "\n",
    "Let's do the same for the training data first and then we will use the same code for the test data as well.\n",
    "\n",
    "The following policy was added to the bucket:\n",
    "\n",
    "{\n",
    "    \"Version\": \"2012-10-17\",\n",
    "    \"Statement\": [\n",
    "        {\n",
    "            \"Sid\": \"Statement1\",\n",
    "            \"Effect\": \"Allow\",\n",
    "            \"Principal\": {\n",
    "                \"AWS\": <insert role based on the printed role>\n",
    "            },\n",
    "            \"Action\": \"s3:*\",\n",
    "            \"Resource\": [\n",
    "                \"arn:aws:s3:::kdfdlkfasdklfjaslkdfjkalsdjfdasklflakdjflksv2/*\",\n",
    "                \"arn:aws:s3:::kdfdlkfasdklfjaslkdfjkalsdjfdasklflakdjflksv2\"\n",
    "            ]\n",
    "        }\n",
    "    ]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2JNY4tSvDXgn",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#buckets created manuallly in s3 and unzippped prior to this step\n",
    "bucket = 'kdfdlkfasdklfjaslkdfjkalsdjfdasklflakdjflks'\n",
    "train_dir = 'train' #prefix for the training directory\n",
    "\n",
    "#Size of image so that each image has the same size\n",
    "SIZE = 64\n",
    "\n",
    "#Empty list to store the training images after they are converted to NumPy arrays\n",
    "train_images = []\n",
    "\n",
    "#Empty list to store the training labels (0 - uninfected, 1 - parasitized)\n",
    "train_labels = []\n",
    "\n",
    "from sagemaker import get_execution_role\n",
    "sagemaker_session = sagemaker.Session()\n",
    "role = get_execution_role()\n",
    "#print(role) - check role and change policy is getting access denied error\n",
    "\n",
    "#set up the connection to s3 bucket\n",
    "conn = boto3.client('s3') #limits to pulling 1,000 files, need multiple calls to API\n",
    "paginator = conn.get_paginator('list_objects') #make multiple calls\n",
    "\n",
    "#additional prefixes within the training directory\n",
    "for folder_name in ['/parasitized/', '/uninfected/']:\n",
    "\n",
    "    #initialize key list\n",
    "    key_list = [ ]\n",
    "\n",
    "    #Path of the folder\n",
    "    contents = paginator.paginate(Bucket=bucket, Prefix=train_dir+folder_name).build_full_result()['Contents'] #extract list of images\n",
    "    for f in contents:\n",
    "        key_list.append(f['Key'])\n",
    "    \n",
    "    #access images from list, skip over first two keys which are \"directories\"\n",
    "    #skipped over directories: 'unzipped/cell_images/train/', 'unzipped/cell_images/train/parasitized/'\n",
    "    for i, key in enumerate(key_list[2:2000]):\n",
    "        try:\n",
    "            s3_object = conn.get_object(Bucket=bucket, Key=key)\n",
    "            body = s3_object['Body']\n",
    "            image = Image.open(body)\n",
    "            image = image.resize((SIZE, SIZE))\n",
    "            train_images.append(np.array(image))\n",
    "\n",
    "            #Creating labels for parasitized and uninfected images\n",
    "            if folder_name=='/parasitized/':\n",
    "                train_labels.append(1)\n",
    "            else:\n",
    "                train_labels.append(0)\n",
    "        except Exception:\n",
    "            pass\n",
    "\n",
    "#Converting lists to arrays\n",
    "train_images = np.array(train_images)\n",
    "train_labels = np.array(train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "id": "My6pm3AFDXk9"
   },
   "outputs": [],
   "source": [
    "#buckets created manuallly in s3 and unzippped prior to this step\n",
    "bucket = 'kdfdlkfasdklfjaslkdfjkalsdjfdasklflakdjflksv2'\n",
    "test_dir = 'cell_images/test' #prefix for the training directory\n",
    "\n",
    "#Size of image so that each image has the same size\n",
    "SIZE = 64\n",
    "\n",
    "#Size of image so that each image has the same size (it must be same as the train image size)\n",
    "SIZE = 64\n",
    "\n",
    "#Empty list to store the testing images after they are converted to NumPy arrays\n",
    "test_images = []\n",
    "\n",
    "#Empty list to store the testing labels (0 - uninfected, 1 - parasitized)\n",
    "test_labels = []\n",
    "\n",
    "#additional prefixes within the training directory\n",
    "for folder_name in ['/parasitized/', '/uninfected/']:\n",
    "\n",
    "    #initialize key list\n",
    "    key_list = [ ]\n",
    "\n",
    "    #Path of the folder\n",
    "    contents = conn.list_objects(Bucket=bucket, Prefix=test_dir+folder_name)['Contents'] #extract list of images\n",
    "    for f in contents:\n",
    "        key_list.append(f['Key'])\n",
    "    \n",
    "    #access images from list, skip over first two keys which are \"directories\"\n",
    "    #skipped over directories: 'unzipped/cell_images/train/', 'unzipped/cell_images/train/parasitized/'\n",
    "    for i, key in enumerate(key_list[2:]):\n",
    "        try:\n",
    "            s3_object = conn.get_object(Bucket=bucket, Key=key)\n",
    "            body = s3_object['Body']\n",
    "            image = Image.open(body)\n",
    "            image = image.resize((SIZE, SIZE))\n",
    "            train_images.append(np.array(image))\n",
    "\n",
    "            #Creating labels for parasitized and uninfected images\n",
    "            if folder_name=='/parasitized/':\n",
    "                train_labels.append(1)\n",
    "            else:\n",
    "                train_labels.append(0)\n",
    "        except Exception:\n",
    "            pass\n",
    "\n",
    "#Converting lists to arrays\n",
    "test_images = np.array(test_images)\n",
    "test_labels = np.array(test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "V_rxFT9iH7pR"
   },
   "source": [
    "###<b> Checking the shape of train and test images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {
    "id": "LA8HJmQp1hU5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(56, 64, 64, 3)\n",
      "(0,)\n"
     ]
    }
   ],
   "source": [
    "print(train_images.shape)\n",
    "print(test_images.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "y3AiiutGIEoy"
   },
   "source": [
    "###<b> Checking the shape of train and test labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {
    "id": "UJ_uvmT61rvx"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000\n",
      "1000\n",
      "1000\n",
      "1000\n"
     ]
    }
   ],
   "source": [
    "# shape of labels \n",
    "train_dir = 'train'\n",
    "for folder_name in ['/parasitized/', '/uninfected/']:\n",
    "\n",
    "    #initialize key list\n",
    "    key_list = [ ]\n",
    "\n",
    "    #Path of the folder\n",
    "    contents = conn.list_objects(Bucket=bucket, Prefix=train_dir+folder_name)['Contents'] #extract list of images\n",
    "    for f in contents:\n",
    "        key_list.append(f['Key'])\n",
    "    print(len(key_list))\n",
    "    print(len(contents))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "A3gtgoubINVX"
   },
   "source": [
    "#####<b> Observations and insights: _____\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZFUMkif7IjlO"
   },
   "source": [
    "### <b>Check the minimum and maximum range of pixel values for train and test images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_gJbhCbMIswX"
   },
   "outputs": [],
   "source": [
    "# try to use min and max function from numpy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_T8WWuSpI6Ih"
   },
   "source": [
    "#####<b> Observations and insights: _____\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ywUFcLSCPIqz"
   },
   "source": [
    "###<b> Count the number of values in both uninfected and parasitized "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xcEb9liBPRlu"
   },
   "outputs": [],
   "source": [
    "# try to use value_counts to count the values\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7U71xb2XJe0t"
   },
   "source": [
    "###<b>Normalize the images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HqzvvNS9IvsP"
   },
   "outputs": [],
   "source": [
    "# try to normalize the train and test images by dividing it by 255 and convert them to float32 using astype function\n",
    "train_images = (___________).astype('float32')\n",
    "test_images = (______________).astype('float32')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lAT1eVTrKiDy"
   },
   "source": [
    "#####<b> Observations and insights: _____"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NG4meNZBKZ5r"
   },
   "source": [
    "###<b> Plot to check if the data is balanced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8N4qohCFIvvI"
   },
   "outputs": [],
   "source": [
    "# you are free to use bar plot or pie-plot or count plot, etc. to plot the labels of train and test data and check if they are balanced\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rGfRJaffLI-C"
   },
   "source": [
    "#####<b> Observations and insights: _____"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "16-Er2edMzsD"
   },
   "source": [
    "### <b>Data Exploration</b>\n",
    "Let's visualize the images from the train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kjhRVQ3-2Pa5"
   },
   "outputs": [],
   "source": [
    "# This code will help you in visualizing both the parasitized and uninfected images\n",
    "np.random.seed(42)\n",
    "plt.figure(1 , figsize = (16 , 16))\n",
    "\n",
    "for n in range(1, 17):\n",
    "    plt.subplot(4, 4, n)\n",
    "    index = int(np.random.randint(0, train_images.shape[0], 1))\n",
    "    if train_labels[index] == 1: \n",
    "        plt.title('parasitized')\n",
    "    else:\n",
    "        plt.title('uninfected')\n",
    "    plt.imshow(train_images[index])\n",
    "    plt.axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OnyS_9IcCZLp"
   },
   "source": [
    "#####<b> Observations and insights: _____"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ay4oo5HrTDha"
   },
   "source": [
    "###<b> Similarly visualize the images with subplot(6,6) and figsize=(12,12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tKmncZ-fTAdD"
   },
   "outputs": [],
   "source": [
    "# Hint: Have a keen look into the number of iterations that the for loop should iterate\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NTG8UaNNNNso"
   },
   "source": [
    "#####<b>Observations and insights:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ifjZ2G0YN20r"
   },
   "source": [
    "###<b> Plotting the mean images for parasitized and uninfected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yN9X0620Iv1a"
   },
   "outputs": [],
   "source": [
    "# function to find the mean\n",
    "def find_mean_img(full_mat, title):\n",
    "    # calculate the average\n",
    "    mean_img = np.mean(full_mat, axis = 0)[0]\n",
    "    # reshape it back to a matrix\n",
    "    plt.imshow(mean_img)\n",
    "    plt.title(f'Average {title}')\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "    return mean_img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mQ4xRQfUOMtm"
   },
   "source": [
    "<b> Mean image for parasitized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SlgCf1-x2gli"
   },
   "outputs": [],
   "source": [
    "# If the label=1 then the image is parasitised and if the label=0 then the image is uninfected\n",
    "parasitized_data=[]                                # Create a list to store the parasitized data\n",
    "for img, label in zip(train_images, train_labels):\n",
    "        if label==1:\n",
    "              parasitized_data.append([img])          \n",
    "\n",
    "parasitized_mean = find_mean_img(np.array(parasitized_data), 'Parasitized')   # find the mean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BkRt1rYIKE24"
   },
   "source": [
    "<b> Mean image for uninfected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ji4w0okiIv6o"
   },
   "outputs": [],
   "source": [
    "# Similarly write the code to find the mean image of uninfected\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Lp9NP8yqPA69"
   },
   "source": [
    "#####<b> Observations and insights: _____"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XzBagGEzHMHB"
   },
   "source": [
    "### <b>Converting RGB to HSV of Images using OpenCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eJFCdE77H1Sg"
   },
   "source": [
    "####<b> Converting the train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "32iwgGz7Iv-E"
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "gfx=[]   # to hold the HSV image array\n",
    "for i in np.arange(0,100,1):\n",
    "  a=cv2.cvtColor(train_images[i],cv2.COLOR_BGR2HSV)\n",
    "  gfx.append(a)\n",
    "gfx=np.array(gfx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "V3mr2iWd2pMK"
   },
   "outputs": [],
   "source": [
    "viewimage=np.random.randint(1,100,5)\n",
    "fig,ax=plt.subplots(1,5,figsize=(18,18))\n",
    "for t,i in zip(range(5),viewimage):\n",
    "  Title=train_labels[i]\n",
    "  ax[t].set_title(Title)\n",
    "  ax[t].imshow(gfx[i])\n",
    "  ax[t].set_axis_off()\n",
    "  fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "P9a7cFllH794"
   },
   "source": [
    "####<b> Converting the test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "N-kUOULrGpBA"
   },
   "outputs": [],
   "source": [
    "# Similarly you can visualize for the images in the test data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Xq4_3hv6J3ad"
   },
   "source": [
    "#####<b>Observations and insights: _____"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "L7x9uDxuJur7"
   },
   "source": [
    "###<b> Processing Images using Gaussian Blurring"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HgkB_-J2KhBQ"
   },
   "source": [
    "####<b> Gaussian Blurring on train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "U7GtZThUI6ug"
   },
   "outputs": [],
   "source": [
    "gbx=[]  ## to hold the blurred images\n",
    "for i in np.arange(0,100,1):\n",
    "  b= cv2.GaussianBlur(train_images[i], (5, 5), 0)\n",
    "  gbx.append(b)\n",
    "gbx=np.array(gbx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "x9qa58ep207S"
   },
   "outputs": [],
   "source": [
    "viewimage=np.random.randint(1,100,5)\n",
    "fig,ax=plt.subplots(1,5,figsize=(18,18))\n",
    "for t,i in zip(range(5),viewimage):\n",
    "  Title=train_labels[i]\n",
    "  ax[t].set_title(Title)\n",
    "  ax[t].imshow(gbx[i])\n",
    "  ax[t].set_axis_off()\n",
    "  fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lTsJkRtCKlYZ"
   },
   "source": [
    "####<b> Gaussian Blurring on test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XbmMGySOKblh"
   },
   "outputs": [],
   "source": [
    "# Similarly you can apply Gaussian blurring for the images in the test data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kkpR8tQFKplr"
   },
   "source": [
    "#####**Observations and insights: _____**\n",
    "\n",
    "**Think About It:** Would blurring help us for this problem statement in any way? What else can we try?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "j1dIGd83e5Th"
   },
   "source": [
    "## **Proposed approach**\n",
    "\n",
    "**Potential techniques:** What different techniques should be explored?<br>\n",
    "**Overall solution design:** What is the potential solution design?<br>\n",
    "**Measures of success:** What are the key measures of success to compare different techniques?<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uEwtI9EIfY5v"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Reference_Notebook_Milestone1_DL.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
